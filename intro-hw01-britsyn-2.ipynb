{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Основы глубинного обучения, майнор ИАД\n\nДомашнее задание 1. Введение в PyTorch. Полносвязные нейронные сети.\nОбщая информация\n\nДата выдачи: 06.10.2021\nМягкий дедлайн: 23:59MSK 25.10.2021\nЖесткий дедлайн: 23:59MSK 28.10.2021\nОценивание и штрафы\n\nМаксимально допустимая оценка за работу — 10 баллов. За каждый день просрочки снимается 1 балл. Сдавать задание после жёсткого дедлайна сдачи нельзя.\nЗадание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\nНеэффективная реализация кода может негативно отразиться на оценке. Также оценка может быть снижена за плохо читаемый код и плохо оформленные графики. Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\nО задании\n\nВ этом задании вам предстоит предсказывать год выпуска песни по некоторым звуковым признакам: данные. В ячейках ниже находится код для загрузки данных. Обратите внимание, что обучающая и тестовая выборки располагаются в одном файле, поэтому НЕ меняйте ячейку, в которой производится деление данных.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport pandas as pd\nimport numpy as np\nimport random\nfrom tqdm.notebook import tqdm\nimport torch.nn.functional as F\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:32:37.907761Z","iopub.execute_input":"2021-10-28T12:32:37.908444Z","iopub.status.idle":"2021-10-28T12:32:39.273070Z","shell.execute_reply.started":"2021-10-28T12:32:37.908344Z","shell.execute_reply":"2021-10-28T12:32:39.272200Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"seed = 228\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:32:39.277351Z","iopub.execute_input":"2021-10-28T12:32:39.277567Z","iopub.status.idle":"2021-10-28T12:32:39.288008Z","shell.execute_reply.started":"2021-10-28T12:32:39.277540Z","shell.execute_reply":"2021-10-28T12:32:39.287102Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"print(torch.cuda.is_available())\ndev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nprint(dev)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:32:39.289512Z","iopub.execute_input":"2021-10-28T12:32:39.289774Z","iopub.status.idle":"2021-10-28T12:32:39.336633Z","shell.execute_reply.started":"2021-10-28T12:32:39.289738Z","shell.execute_reply":"2021-10-28T12:32:39.335657Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!wget -O data.txt.zip https://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:32:39.338251Z","iopub.execute_input":"2021-10-28T12:32:39.338969Z","iopub.status.idle":"2021-10-28T12:32:43.206401Z","shell.execute_reply.started":"2021-10-28T12:32:39.338933Z","shell.execute_reply":"2021-10-28T12:32:43.205634Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('data.txt.zip', header=None)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:32:43.209380Z","iopub.execute_input":"2021-10-28T12:32:43.209656Z","iopub.status.idle":"2021-10-28T12:32:55.371363Z","shell.execute_reply.started":"2021-10-28T12:32:43.209620Z","shell.execute_reply":"2021-10-28T12:32:55.370689Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Задание 0. (0 баллов, но при невыполнении максимум за все задание — 0 баллов)\nМы будем использовать RMSE как метрику качества. Для самого первого бейзлайна обучите Ridge регрессию из sklearn. Кроме того, посчитайте качество при наилучшем константном прогнозе.","metadata":{}},{"cell_type":"code","source":"X = df.iloc[:, 1:].values\ny = df.iloc[:, 0].values\n\ntrain_size = 463715\nX_train = X[:train_size, :]\ny_train = y[:train_size]\nX_test = X[train_size:, :]\ny_test = y[train_size:]","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:32:55.372665Z","iopub.execute_input":"2021-10-28T12:32:55.373527Z","iopub.status.idle":"2021-10-28T12:32:55.488882Z","shell.execute_reply.started":"2021-10-28T12:32:55.373484Z","shell.execute_reply":"2021-10-28T12:32:55.487996Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\n\nrid = Ridge(alpha=0.1, normalize=True).fit(X_train, y_train)\nrmse = np.sqrt(mean_squared_error(y_test,rid.predict(X_test)))","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:32:55.490322Z","iopub.execute_input":"2021-10-28T12:32:55.492073Z","iopub.status.idle":"2021-10-28T12:32:56.755127Z","shell.execute_reply.started":"2021-10-28T12:32:55.492026Z","shell.execute_reply":"2021-10-28T12:32:56.754246Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"rmse","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:32:56.760173Z","iopub.execute_input":"2021-10-28T12:32:56.760656Z","iopub.status.idle":"2021-10-28T12:32:56.770698Z","shell.execute_reply.started":"2021-10-28T12:32:56.760610Z","shell.execute_reply":"2021-10-28T12:32:56.769808Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Задание 1. (максимум 10 баллов)\n\nРеализуйте обучение и тестирование нейронной сети для предоставленного вам набора данных. Соотношение между полученным значением метрики на тестовой выборке и баллами за задание следующее:\n\n- $\\text{RMSE} \\le 9.00 $ &mdash; 4 балла\n- $\\text{RMSE} \\le 8.90 $ &mdash; 6 баллов\n- $\\text{RMSE} \\le 8.80 $ &mdash; 8 баллов\n- $\\text{RMSE} \\le 8.75 $ &mdash; 10 баллов\n\nЕсть несколько правил, которых вам нужно придерживаться:\n\n- Весь пайплайн обучения должен быть написан на PyTorch. При этом вы можете пользоваться другими библиотеками (`numpy`, `sklearn` и пр.), но только для обработки данных. То есть как угодно трансформировать данные и считать метрики с помощью этих библиотек можно, а импортировать модели из `sklearn` и выбивать с их помощью требуемое качество &mdash; нельзя. Также нельзя пользоваться библиотеками, для которых сам PyTorch является зависимостью.\n\n- Мы никак не ограничиваем ваш выбор архитектуры модели, но скорее всего вам будет достаточно полносвязной нейронной сети.\n\n- Для обучения запрещается использовать какие-либо иные данные, кроме обучающей выборки.\n\n- Ансамблирование моделей запрещено.\n\n### Полезные советы:\n\n- Очень вряд ли, что у вас с первого раза получится выбить качество на 10 баллов, поэтому пробуйте разные архитектуры, оптимизаторы и значения гиперпараметров. В идеале при запуске каждого нового эксперимента вы должны менять что-то одно, чтобы точно знать, как этот фактор влияет на качество.\n\n- Тот факт, что мы занимаемся глубинным обучением, не означает, что стоит забывать про приемы, использующиеся в классическом машинном обучении. Так что обязательно проводите исследовательский анализ данных, отрисовывайте нужные графики и не забывайте про масштабирование и подбор гиперпараметров.\n\n- Вы наверняка столкнетесь с тем, что ваша нейронная сеть будет сильно переобучаться. Для нейросетей существуют специальные методы регуляризации, например, dropout ([статья](https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)) и weight decay ([блогпост](https://towardsdatascience.com/weight-decay-l2-regularization-90a9e17713cd)). Они, разумеется, реализованы в PyTorch. Попробуйте поэкспериментировать с ними.\n\n- Если вы чего-то не знаете, не гнушайтесь гуглить. В интернете очень много полезной информации, туториалов и советов по глубинному обучению в целом и по PyTorch в частности. Но не забывайте, что за скатанный код без ссылки на источник придется ответить по всей строгости!\n\n- Если вы сразу реализуете обучение на GPU, то у вас будет больше времени на эксперименты, так как любые вычисления будут работать быстрее. Google Colab предоставляет несколько GPU-часов (обычно около 8-10) в сутки бесплатно.\n\n- Чтобы отладить код, можете обучаться на небольшой части данных или даже на одном батче. Если лосс на обучающей выборке не падает, то что-то точно идет не так!\n\n- Пользуйтесь утилитами, которые вам предоставляет PyTorch (например, Dataset и Dataloader). Их специально разработали для упрощения разработки пайплайна обучения.\n\n- Скорее всего вы захотите отслеживать прогресс обучения. Для создания прогресс-баров есть удобная библиотека `tqdm`.\n\n- Быть может, вы захотите, чтобы графики рисовались прямо во время обучения. Можете воспользоваться функцией [clear_output](http://ipython.org/ipython-doc/dev/api/generated/IPython.display.html#IPython.display.clear_output), чтобы удалять старый график и рисовать новый на его месте.\n\n**ОБЯЗАТЕЛЬНО** рисуйте графики зависимости лосса/метрики на обучающей и тестовой выборках в зависимости от времени обучения. Если обучение занимает относительно небольшое число эпох, то лучше рисовать зависимость от номера шага обучения, если же эпох больше, то рисуйте зависимость по эпохам. Если проверяющий не увидит такого графика для вашей лучшей модели, то он в праве снизить баллы за задание.\n\n**ВАЖНО!** Ваше решение должно быть воспроизводимым. Если это не так, то проверяющий имеет право снизить баллы за задание. Чтобы зафиксировать random seed, воспользуйтесь функцией из ячейки ниже.","metadata":{}},{"cell_type":"code","source":"def set_random_seed(seed):\n    torch.backends.cudnn.deterministic = True\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\nset_random_seed(228)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:32:56.771859Z","iopub.execute_input":"2021-10-28T12:32:56.772442Z","iopub.status.idle":"2021-10-28T12:32:56.779933Z","shell.execute_reply.started":"2021-10-28T12:32:56.772401Z","shell.execute_reply":"2021-10-28T12:32:56.778982Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Проверим данные:","metadata":{}},{"cell_type":"code","source":"print(df.dtypes.unique())\nprint(df.isna().values.any())\n# пустых ячеек нет, данные все численные ","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:32:56.781253Z","iopub.execute_input":"2021-10-28T12:32:56.781625Z","iopub.status.idle":"2021-10-28T12:32:56.900361Z","shell.execute_reply.started":"2021-10-28T12:32:56.781572Z","shell.execute_reply":"2021-10-28T12:32:56.899539Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import QuantileTransformer\nscaler = QuantileTransformer()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:32:56.901645Z","iopub.execute_input":"2021-10-28T12:32:56.901940Z","iopub.status.idle":"2021-10-28T12:32:56.905731Z","shell.execute_reply.started":"2021-10-28T12:32:56.901876Z","shell.execute_reply":"2021-10-28T12:32:56.904888Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"X = df.iloc[:, 1:].values\ny = df.iloc[:, 0].values\n\ntrain_size = 463715\n\nX_train = torch.tensor(X[:train_size, :])\nX_train = scaler.fit_transform(X_train)\ny_train = torch.tensor(y[:train_size])\nX_test = torch.tensor(X[train_size:, :])\nX_test = scaler.fit_transform(X_test)\ny_test = torch.tensor(y[train_size:])","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:32:56.907084Z","iopub.execute_input":"2021-10-28T12:32:56.907524Z","iopub.status.idle":"2021-10-28T12:33:08.796655Z","shell.execute_reply.started":"2021-10-28T12:32:56.907485Z","shell.execute_reply":"2021-10-28T12:33:08.795853Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"y_test","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:33:08.798045Z","iopub.execute_input":"2021-10-28T12:33:08.798304Z","iopub.status.idle":"2021-10-28T12:33:08.828188Z","shell.execute_reply.started":"2021-10-28T12:33:08.798270Z","shell.execute_reply":"2021-10-28T12:33:08.827464Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Класс данных:\nСпасибо Кэгл https://www.kaggle.com/matthewmasters/pytorch-nn-starter-baseline-train","metadata":{}},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n    \"\"\"\n    Our random dataset\n    \"\"\"\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n        \n    def __len__(self):\n        return len(self.x)\n    \n    def __getitem__(self, idx):\n        return self.x[idx, :], self.y[idx]","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:33:08.831229Z","iopub.execute_input":"2021-10-28T12:33:08.831447Z","iopub.status.idle":"2021-10-28T12:33:08.836389Z","shell.execute_reply.started":"2021-10-28T12:33:08.831415Z","shell.execute_reply":"2021-10-28T12:33:08.835676Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"x = torch.tensor(X_train).to(dev)\ny = torch.tensor(y_train).to(dev)\n\ntrain = Dataset(x, y)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:33:08.837493Z","iopub.execute_input":"2021-10-28T12:33:08.838264Z","iopub.status.idle":"2021-10-28T12:33:11.681135Z","shell.execute_reply.started":"2021-10-28T12:33:08.838223Z","shell.execute_reply":"2021-10-28T12:33:11.680332Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"x = torch.tensor(X_test).to(dev)\ny = torch.tensor(y_test).to(dev)\n\ntest = Dataset(x, y)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:33:11.684267Z","iopub.execute_input":"2021-10-28T12:33:11.684479Z","iopub.status.idle":"2021-10-28T12:33:11.720699Z","shell.execute_reply.started":"2021-10-28T12:33:11.684453Z","shell.execute_reply":"2021-10-28T12:33:11.720006Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Даталоудер:","metadata":{}},{"cell_type":"code","source":"train_dataloader = torch.utils.data.DataLoader(train, batch_size=64)\ntest_dataloader = torch.utils.data.DataLoader(test, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:33:11.721890Z","iopub.execute_input":"2021-10-28T12:33:11.722326Z","iopub.status.idle":"2021-10-28T12:33:11.729037Z","shell.execute_reply.started":"2021-10-28T12:33:11.722285Z","shell.execute_reply":"2021-10-28T12:33:11.726474Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Модель","metadata":{}},{"cell_type":"code","source":"class Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(90, 1500),\n            nn.Dropout(0.2),\n            nn.BatchNorm1d(1500),\n            nn.SiLU(),\n            nn.Linear(1500, 500),\n            nn.BatchNorm1d(500),\n            nn.SiLU(),\n            nn.Linear(500, 1)\n \n        )\n    \n    def forward(self, features):\n        return self.layers(features.float())\n\nmodel = Network().to(dev)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:33:11.730632Z","iopub.execute_input":"2021-10-28T12:33:11.731250Z","iopub.status.idle":"2021-10-28T12:33:11.769491Z","shell.execute_reply.started":"2021-10-28T12:33:11.731208Z","shell.execute_reply":"2021-10-28T12:33:11.768819Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Оптимизатор","metadata":{}},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr = 0.001)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:33:11.770833Z","iopub.execute_input":"2021-10-28T12:33:11.771106Z","iopub.status.idle":"2021-10-28T12:33:11.775587Z","shell.execute_reply.started":"2021-10-28T12:33:11.771063Z","shell.execute_reply":"2021-10-28T12:33:11.774718Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"критерий","metadata":{}},{"cell_type":"code","source":"def RMSELoss(yhat,y):\n    return torch.sqrt(torch.mean((yhat-y)**2))\n\ncriterion = RMSELoss","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:33:11.777447Z","iopub.execute_input":"2021-10-28T12:33:11.778043Z","iopub.status.idle":"2021-10-28T12:33:11.785497Z","shell.execute_reply.started":"2021-10-28T12:33:11.778002Z","shell.execute_reply":"2021-10-28T12:33:11.784721Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"трейн:","metadata":{}},{"cell_type":"code","source":"def train(model, optimizer, criterion, train_dataloader, test_dataloader):\n    '''\n    params:\n        model - torch.nn.Module to be fitted\n        optimizer - model optimizer\n        criterion - loss function from torch.nn\n        train_dataloader - torch.utils.data.Dataloader with train set\n        test_dataloader - torch.utils.data.Dataloader with test set\n                      (if you wish to validate during training)\n    '''\n    for epoch in range(10):\n        print('Epoch # {}'.format(epoch))\n        train_loss = []\n        for x_train, y_train in tqdm(train_dataloader):    # берем батч из трейн лоадера\n            y_pred = model(x_train)                        # делаем предсказания\n            loss = criterion(y_pred, y_train)\n            loss.backward()                                # считаем градиенты обратным проходом\n            optimizer.step()                               # обновляем параметры сети\n            optimizer.zero_grad()                          # обнуляем посчитанные градиенты параметров\n            with torch.no_grad():                          # на валидации запрещаем фреймворку считать градиенты по параметрам # берем батч из вал лоадера\n                y_pred = model(x_train)                  # делаем предсказания\n                loss = criterion(y_pred, y_train).to('cpu')        # считаем лосс\n                train_loss.append(loss.numpy())\n    \n        model.eval()\n        val_loss = []\n        \n        with torch.no_grad():\n            for x_val, y_val in tqdm(test_dataloader):\n                y_pred = model(x_val)\n                y_val.cpu\n                y_pred.cpu\n                loss = criterion(y_pred, y_val).to('cpu')\n                val_loss.append(loss.numpy())\n        print(f\"Epoch: {epoch},train_loss: {np.mean(train_loss)}, test_loss: {np.mean(val_loss)}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:33:11.787958Z","iopub.execute_input":"2021-10-28T12:33:11.788577Z","iopub.status.idle":"2021-10-28T12:33:11.799065Z","shell.execute_reply.started":"2021-10-28T12:33:11.788539Z","shell.execute_reply":"2021-10-28T12:33:11.798356Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train(model, optimizer, criterion, train_dataloader, test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T12:33:11.801627Z","iopub.execute_input":"2021-10-28T12:33:11.802910Z","iopub.status.idle":"2021-10-28T12:37:28.559619Z","shell.execute_reply.started":"2021-10-28T12:33:11.802869Z","shell.execute_reply":"2021-10-28T12:37:28.558899Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Задание 2. (0 баллов, но при невыполнении максимум за все задание &mdash; 0 баллов)\n\nНапишите небольшой отчет о том, как вы добились полученного качества: какие средства использовали и какие эксперименты проводили. Подробно расскажите об архитектурах и значениях гиперпараметров, а также какие метрики на тесте они показывали. Чтобы отчет был зачтен, необходимо привести хотя бы 3 эксперимента.","metadata":{}},{"cell_type":"markdown","source":"### По порядку\n* Я скейлил только трейн из данных, а скейлить тарргеты особо не помогало\n* Очееь сильно разнились результаты пока я не зафиксировал сид... да, функцию надо не только инцииализировать, но и выполнить\n* Попробовал много оптимизаторов - Adagrad, SGD, Adam, но AdamW сходился быстрее всех и вообще сходился\n* пытался сделать РМСЕ и через торч, и через нумпай, но остановился на торче из-за удобства передачи данных в функцию\n* по архитектуре сети - опирался на то что в эталонном решение, по словам лектора, было два слоя - пытался эксперементировать с функциями активации от релу и сигмоиды до силу. дропауты не сильно, но улучшали модель\n* на табличных данных мне пока что больше нарвистя бустинг:)\n* даталоудеры и классы для данных - тоже неочевидная штука, пока не начнешь их делать) на 5к размерах батча ничего вообще не сходилось - снижал до 64 и улучшались метрики\n* А ещё кеггл ноутбуки - топ!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}