{"cells":[{"cell_type":"markdown","metadata":{"cell_id":1,"id":"kr9vAeEQlRVG"},"source":["# Домашнее задание 2. Классификация изображений."]},{"cell_type":"markdown","metadata":{"cell_id":3,"id":"BxX49gLclRVJ"},"source":["В этом задании потребуется обучить классификатор изображений. Будем работать с датасетом, название которого раскрывать не будем. Можете посмотреть самостоятельно на картинки, которые в есть датасете. В нём 200 классов и около 5 тысяч картинок на каждый класс. Классы пронумерованы, как нетрудно догадаться, от 0 до 199. Скачать датасет можно вот [тут](https://yadi.sk/d/BNR41Vu3y0c7qA).\n","\n","Структура датасета простая -- есть директории train/ и val/, в которых лежат обучающие и валидационные данные. В train/ и val/ лежат директориии, соответствующие классам изображений, в которых лежат, собственно, сами изображения.\n"," \n","__Задание__. Необходимо выполнить любое из двух заданий\n","\n","1) Добейтесь accuracy **на валидации не менее 0.44**. В этом задании **запрещено** пользоваться предобученными моделями и ресайзом картинок. \n","\n","2) Добейтесь accuracy **на валидации не менее 0.84**. В этом задании делать ресайз и использовать претрейн можно. \n","\n","Напишите краткий отчёт о проделанных экспериментах. Что сработало и что не сработало? Почему вы решили, сделать так, а не иначе? Обязательно указывайте ссылки на чужой код, если вы его используете. Обязательно ссылайтесь на статьи / блогпосты / вопросы на stackoverflow / видосы от ютуберов-машинлернеров / курсы / подсказки от Дяди Васи и прочие дополнительные материалы, если вы их используете. \n","\n","Ваш код обязательно должен проходить все `assert`'ы ниже.\n","\n","Необходимо написать функции `train_one_epoch`, `train` и `predict` по шаблонам ниже (во многом повторяют примеры с семинаров).Обратите особое внимание на функцию `predict`: она должна возвращать список лоссов по всем объектам даталоадера, список предсказанных классов для каждого объекта из даталоалера и список настоящих классов для каждого объекта в даталоадере (и именно в таком порядке).\n","\n","__Использовать внешние данные для обучения строго запрещено в обоих заданиях. Также запрещено обучаться на валидационной выборке__.\n","\n","\n","__Критерии оценки__: Оценка вычисляется по простой формуле: `min(10, 10 * Ваша accuracy / 0.44)` для первого задания и `min(10, 10 * (Ваша accuracy - 0.5) / 0.34)` для второго. Оценка округляется до десятых по арифметическим правилам. Если вы выполнили оба задания, то берется максимум из двух оценок.\n","\n","__Бонус__. Вы получаете 5 бонусных баллов если справляетесь с обоими заданиями на 10 баллов (итого 15 баллов). В противном случае выставляется максимальная из двух оценок и ваш бонус равен нулю.\n","\n","__Советы и указания__:\n"," - Наверняка вам потребуется много гуглить о классификации и о том, как заставить её работать. Это нормально, все гуглят. Но не забывайте, что нужно быть готовым за скатанный код отвечать :)\n"," - Используйте аугментации. Для этого пользуйтесь модулем `torchvision.transforms` или библиотекой [albumentations](https://github.com/albumentations-team/albumentations)\n"," - Можно обучать с нуля или файнтюнить (в зависимости от задания) модели из `torchvision`.\n"," - Рекомендуем написать вам сначала класс-датасет (или воспользоваться классом `ImageFolder`), который возвращает картинки и соответствующие им классы, а затем функции для трейна по шаблонам ниже. Однако делать это мы не заставляем. Если вам так неудобно, то можете писать код в удобном стиле. Однако учтите, что чрезмерное изменение нижеперечисленных шаблонов увеличит количество вопросов к вашему коду и повысит вероятность вызова на защиту :)\n"," - Валидируйте. Трекайте ошибки как можно раньше, чтобы не тратить время впустую.\n"," - Чтобы быстро отладить код, пробуйте обучаться на маленькой части датасета (скажем, 5-10 картинок просто чтобы убедиться что код запускается). Когда вы поняли, что смогли всё отдебажить, переходите обучению по всему датасету\n"," - На каждый запуск делайте ровно одно изменение в модели/аугментации/оптимайзере, чтобы понять, что и как влияет на результат.\n"," - Фиксируйте random seed.\n"," - Начинайте с простых моделей и постепенно переходите к сложным. Обучение лёгких моделей экономит много времени.\n"," - Ставьте расписание на learning rate. Уменьшайте его, когда лосс на валидации перестаёт убывать.\n"," - Советуем использовать GPU. Если у вас его нет, используйте google colab. Если вам неудобно его использовать на постоянной основе, напишите и отладьте весь код локально на CPU, а затем запустите уже написанный ноутбук в колабе. Авторское решение задания достигает требуемой точности в колабе за 15 минут обучения.\n"," \n","Good luck & have fun! :)"]},{"cell_type":"code","execution_count":123,"metadata":{"execution":{"iopub.execute_input":"2021-11-21T18:32:29.347011Z","iopub.status.busy":"2021-11-21T18:32:29.346764Z","iopub.status.idle":"2021-11-21T18:32:29.350734Z","shell.execute_reply":"2021-11-21T18:32:29.349898Z","shell.execute_reply.started":"2021-11-21T18:32:29.346982Z"},"trusted":true},"outputs":[],"source":["# Доска почета тех, благодаря кому я сдал это дз\n","# 5 семинар\n","# https://www.kaggle.com/liweicai/resnet-18-data-augmentation-with-torchvision\n","# https://www.youtube.com/watch?v=ovZ_54IUSU4\n","# https://www.programcreek.com/python/example/105102/torchvision.datasets.ImageFolder\n","# https://www.kaggle.com/appetukhov/simple-cnn-baseline-with-pytroch-for-beginners/data\n","# https://www.kaggle.com/darbin/ka-task-8-2-tiny-image-net-cnn-ru/data\n","# Работа была сделана в Kaggle Notebook\n","# Респект Никите Захарову, который залил на кеггл данные по URL https://www.kaggle.com/amiralex/cs-hse-hw2-ogo/"]},{"cell_type":"code","execution_count":124,"metadata":{"cell_id":4,"execution":{"iopub.execute_input":"2021-11-21T18:32:33.304718Z","iopub.status.busy":"2021-11-21T18:32:33.304455Z","iopub.status.idle":"2021-11-21T18:32:33.312742Z","shell.execute_reply":"2021-11-21T18:32:33.311216Z","shell.execute_reply.started":"2021-11-21T18:32:33.304688Z"},"id":"LKcSNj4tlRVK","trusted":true},"outputs":[],"source":["import os\n","import sys\n","from pathlib import Path\n","import numpy as np \n","import pandas as pd \n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import mean_squared_error\n","from scipy.spatial.distance import euclidean\n","import warnings\n","warnings.filterwarnings('ignore')\n","from PIL import Image\n","import torch \n","from torch import nn\n","import math\n","from torch import optim\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","import random\n","from torchvision.datasets import ImageFolder\n","from torchvision.transforms import ToTensor, CenterCrop, RandomHorizontalFlip, RandomAffine, Compose, Normalize, RandomHorizontalFlip, RandomErasing, RandomPerspective, RandomRotation, Resize, ToPILImage, Pad\n","from sklearn.metrics import accuracy_score\n","from torch.optim.lr_scheduler import CosineAnnealingLR"]},{"cell_type":"code","execution_count":127,"metadata":{"execution":{"iopub.execute_input":"2021-11-21T18:32:38.807136Z","iopub.status.busy":"2021-11-21T18:32:38.806318Z","iopub.status.idle":"2021-11-21T18:32:38.934728Z","shell.execute_reply":"2021-11-21T18:32:38.932553Z","shell.execute_reply.started":"2021-11-21T18:32:38.807085Z"},"trusted":true},"outputs":[{"data":{"text/plain":["149"]},"execution_count":127,"metadata":{},"output_type":"execute_result"}],"source":["import gc \n","try:\n","    del val_data, train_data, model, train_dataloader, val_dataloader\n","except:\n","    pass\n","torch.cuda.empty_cache()\n","torch.cuda.memory_summary(device=None, abbreviated=False)\n","gc.collect()"]},{"cell_type":"code","execution_count":128,"metadata":{"execution":{"iopub.execute_input":"2021-11-21T18:32:40.208738Z","iopub.status.busy":"2021-11-21T18:32:40.207875Z","iopub.status.idle":"2021-11-21T18:32:40.214409Z","shell.execute_reply":"2021-11-21T18:32:40.213507Z","shell.execute_reply.started":"2021-11-21T18:32:40.208685Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","cuda\n"]}],"source":["#check GPU\n","print(torch.cuda.is_available())\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":129,"metadata":{"execution":{"iopub.execute_input":"2021-11-21T18:32:40.547110Z","iopub.status.busy":"2021-11-21T18:32:40.546542Z","iopub.status.idle":"2021-11-21T18:32:40.552114Z","shell.execute_reply":"2021-11-21T18:32:40.551093Z","shell.execute_reply.started":"2021-11-21T18:32:40.547071Z"},"trusted":true},"outputs":[],"source":["seed = 456\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"markdown","metadata":{"id":"RytEDW0ylRVN"},"source":["### Подготовка данных"]},{"cell_type":"code","execution_count":130,"metadata":{"execution":{"iopub.execute_input":"2021-11-21T18:32:42.860195Z","iopub.status.busy":"2021-11-21T18:32:42.859485Z","iopub.status.idle":"2021-11-21T18:32:43.941530Z","shell.execute_reply":"2021-11-21T18:32:43.940798Z","shell.execute_reply.started":"2021-11-21T18:32:42.860158Z"},"trusted":true},"outputs":[],"source":["train_data = ImageFolder(\n","    root='../input/cs-hse-hw2-ogo/dataset/dataset/train', transform=Compose(\n","        [\n","            Resize((256, 256)),\n","            CenterCrop((224, 224)),\n","            RandomHorizontalFlip(p=0.5),\n","            RandomPerspective(),\n","            RandomAffine(degrees=30, translate=(0.2, 0.2), shear=0.2),\n","            ToTensor(), \n","            Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), \n","        ]))\n","val_data = ImageFolder(\n","    root='../input/cs-hse-hw2-ogo/dataset/dataset/val', transform=Compose(\n","        [\n","            Resize((256, 256)),\n","            CenterCrop((224, 224)),\n","            ToTensor(), \n","            Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), \n","        ]))"]},{"cell_type":"markdown","metadata":{},"source":["Даталоудеры"]},{"cell_type":"code","execution_count":131,"metadata":{"execution":{"iopub.execute_input":"2021-11-21T18:32:48.929651Z","iopub.status.busy":"2021-11-21T18:32:48.928951Z","iopub.status.idle":"2021-11-21T18:32:48.934437Z","shell.execute_reply":"2021-11-21T18:32:48.933685Z","shell.execute_reply.started":"2021-11-21T18:32:48.929609Z"},"trusted":true},"outputs":[],"source":["train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n","val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=False)"]},{"cell_type":"code","execution_count":132,"metadata":{"cell_id":6,"execution":{"iopub.execute_input":"2021-11-21T18:32:50.081446Z","iopub.status.busy":"2021-11-21T18:32:50.080646Z","iopub.status.idle":"2021-11-21T18:32:50.110117Z","shell.execute_reply":"2021-11-21T18:32:50.109373Z","shell.execute_reply.started":"2021-11-21T18:32:50.081394Z"},"id":"mrg4Yj0VlRVP","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tests passed\n"]}],"source":["# Just very simple sanity checks\n","assert isinstance(train_data[0], tuple)\n","assert len(train_data[0]) == 2\n","assert isinstance(train_data[1][1], int)\n","print(\"tests passed\")"]},{"cell_type":"markdown","metadata":{"id":"8RlSlmyjlRVP"},"source":["### Вспомогательные функции, реализация модели"]},{"cell_type":"code","execution_count":142,"metadata":{"cell_id":7,"execution":{"iopub.execute_input":"2021-11-21T20:42:46.308387Z","iopub.status.busy":"2021-11-21T20:42:46.308153Z","iopub.status.idle":"2021-11-21T20:42:46.318134Z","shell.execute_reply":"2021-11-21T20:42:46.317333Z","shell.execute_reply.started":"2021-11-21T20:42:46.308361Z"},"id":"yYG2-Cq8lRVQ","trusted":true},"outputs":[],"source":["def train_one_epoch(model, data_loader, optimizer, return_losses, criterion, scheduler, device):\n","    model.train()\n","    total_loss = 0\n","    num_batches = 0\n","    all_losses = []\n","    total_predictions = np.array([])#.reshape((0, ))\n","    total_labels = np.array([])#.reshape((0, ))\n","    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n","        for images, labels in data_loader:\n","            # Move Batch to GPU\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            predicted = model(images)\n","            loss = criterion(predicted, labels)\n","            # Update weights\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","            optimizer.zero_grad()\n","            # Update descirption for tqdm\n","            accuracy = (predicted.argmax(1) == labels).float().mean()\n","            prbar.set_description(\n","                f\"Loss: {round(loss.item(), 4)} \"\n","                f\"Accuracy: {round(accuracy.item() * 100, 4)}\"\n","            )\n","            prbar.update(1)\n","            total_loss += loss.item()\n","            total_predictions = np.append(total_predictions, predicted.argmax(1).cpu().detach().numpy())\n","            total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n","            num_batches += 1\n","            all_losses.append(loss.detach().item())\n","    metrics = {\"loss\": total_loss / num_batches}\n","    metrics.update({\"accuracy\": (total_predictions == total_labels).mean()})\n","    if return_losses:\n","        return metrics, all_losses\n","    else:\n","        return metrics"]},{"cell_type":"code","execution_count":134,"metadata":{"execution":{"iopub.execute_input":"2021-11-21T18:32:53.195909Z","iopub.status.busy":"2021-11-21T18:32:53.195443Z","iopub.status.idle":"2021-11-21T18:32:53.203083Z","shell.execute_reply":"2021-11-21T18:32:53.202064Z","shell.execute_reply.started":"2021-11-21T18:32:53.195872Z"},"trusted":true},"outputs":[],"source":["def train(model, epochs, train_dataloader, val_dataloader, optimizer, criterion, device):\n","    all_train_losses = []\n","    epoch_train_losses = []\n","    epoch_eval_losses = []\n","    for epoch in range(epochs):\n","        # Train step\n","        print(f\"Train Epoch: {epoch}\")\n","        train_metrics, one_epoch_train_losses = train_one_epoch(\n","            model=model,\n","            data_loader=train_dataloader,\n","            optimizer=optimizer,\n","            return_losses=True,\n","            criterion=criterion,\n","            device=device\n","        )\n","        # Save Train losses\n","        all_train_losses.extend(one_epoch_train_losses)\n","        epoch_train_losses.append(train_metrics[\"loss\"])\n","        # Eval step\n","        print(f\"Validation Epoch: {epoch}\")\n","        with torch.no_grad():\n","            validation_metrics, predicted_labels, true_labels = validate(\n","                model=model,\n","                data_loader=val_dataloader,\n","                criterion=criterion\n","            )\n","        print('Metrics of an epoch: ', validation_metrics)\n","        # Save eval losses\n","        epoch_eval_losses.append(validation_metrics[\"loss\"])"]},{"cell_type":"code","execution_count":135,"metadata":{"execution":{"iopub.execute_input":"2021-11-21T18:32:53.619207Z","iopub.status.busy":"2021-11-21T18:32:53.618662Z","iopub.status.idle":"2021-11-21T18:32:53.628168Z","shell.execute_reply":"2021-11-21T18:32:53.627470Z","shell.execute_reply.started":"2021-11-21T18:32:53.619169Z"},"trusted":true},"outputs":[],"source":["\n","def validate(model, data_loader, criterion, device=\"cuda:0\"):\n","    model = model.eval()\n","    total_loss = 0\n","    num_batches = 0\n","    total_predictions = np.array([])\n","    total_labels = np.array([])\n","    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n","        for images, labels in data_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            predicted = model(images)\n","            loss = criterion(predicted, labels)\n","            accuracy = (predicted.argmax(1) == labels).float().mean()\n","            prbar.set_description(\n","                f\"Loss: {round(loss.item(), 4)} \"\n","                f\"Accuracy: {round(accuracy.item() * 100, 4)}\"\n","            )\n","            prbar.update(1)\n","            total_loss += loss.item()\n","            total_predictions = np.append(total_predictions, predicted.argmax(1).cpu().detach().numpy())\n","            total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n","            num_batches += 1\n","    metrics = {\"loss\": total_loss / num_batches}\n","    metrics.update({\"accuracy\": (total_predictions == total_labels).mean()})\n","    return metrics, total_predictions, total_labels\n","        "]},{"cell_type":"markdown","metadata":{"id":"MxR3gfcilRVW"},"source":["### Обучение модели, запуски экспериментов"]},{"cell_type":"code","execution_count":137,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2021-11-21T18:32:58.210070Z","iopub.status.busy":"2021-11-21T18:32:58.209776Z","iopub.status.idle":"2021-11-21T18:32:58.413523Z","shell.execute_reply":"2021-11-21T18:32:58.412860Z","shell.execute_reply.started":"2021-11-21T18:32:58.210015Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=200, bias=True)\n",")"]},"execution_count":137,"metadata":{},"output_type":"execute_result"}],"source":["from torchvision.models import resnet18\n","from torchvision.models import mobilenet_v2\n","model = resnet18(pretrained=True)\n","model.fc = nn.Linear(512, 200)\n","model.to(device)"]},{"cell_type":"code","execution_count":138,"metadata":{"execution":{"iopub.execute_input":"2021-11-21T18:33:02.588606Z","iopub.status.busy":"2021-11-21T18:33:02.588073Z","iopub.status.idle":"2021-11-21T18:33:02.593267Z","shell.execute_reply":"2021-11-21T18:33:02.592065Z","shell.execute_reply.started":"2021-11-21T18:33:02.588566Z"},"trusted":true},"outputs":[],"source":["for param in model.parameters():\n","    param.requires_grad = True"]},{"cell_type":"code","execution_count":139,"metadata":{"cell_id":8,"execution":{"iopub.execute_input":"2021-11-21T18:33:16.624003Z","iopub.status.busy":"2021-11-21T18:33:16.623677Z","iopub.status.idle":"2021-11-21T18:33:16.636862Z","shell.execute_reply":"2021-11-21T18:33:16.635815Z","shell.execute_reply.started":"2021-11-21T18:33:16.623971Z"},"id":"JXFJ6oS8lRVX","scrolled":true,"trusted":true},"outputs":[],"source":["# model = model\n","optimizer = optim.AdamW(model.parameters(), lr=0.0001, amsgrad=True)\n","criterion = nn.CrossEntropyLoss()\n","n_epochs = 10\n","scheduler = CosineAnnealingLR(optimizer, 1)"]},{"cell_type":"markdown","metadata":{"cell_id":9,"id":"CesoOl6BlRVY"},"source":["Простой тест на проверку правильности написанного кода"]},{"cell_type":"code","execution_count":145,"metadata":{"cell_id":10,"execution":{"iopub.execute_input":"2021-11-21T20:50:43.574093Z","iopub.status.busy":"2021-11-21T20:50:43.573809Z","iopub.status.idle":"2021-11-21T20:51:15.966450Z","shell.execute_reply":"2021-11-21T20:51:15.965543Z","shell.execute_reply.started":"2021-11-21T20:50:43.574061Z"},"id":"B_LB2jn6lRVY","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loss: 0.8395 Accuracy: 81.25: 100%|██████████| 157/157 [00:32<00:00,  4.85it/s]  \n","tests passed\n"]}],"source":["all_losses, predicted_labels, true_labels = validate(model, val_dataloader, criterion, device)\n","assert len(predicted_labels) == len(val_data)\n","accuracy = (predicted_labels == val_data.targets).mean()\n","print(\"tests passed\")"]},{"cell_type":"markdown","metadata":{"cell_id":11,"id":"tS-LLiXUlRVY"},"source":["Запустить обучение можно в ячейке ниже."]},{"cell_type":"code","execution_count":140,"metadata":{"cell_id":12,"execution":{"iopub.execute_input":"2021-11-21T18:33:22.258881Z","iopub.status.busy":"2021-11-21T18:33:22.258335Z","iopub.status.idle":"2021-11-21T20:42:46.035572Z","shell.execute_reply":"2021-11-21T20:42:46.034717Z","shell.execute_reply.started":"2021-11-21T18:33:22.258841Z"},"id":"ECIzZ_RYlRVZ","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Epoch: 0\n","Loss: 1.707 Accuracy: 65.625: 100%|██████████| 1563/1563 [12:15<00:00,  2.13it/s]  \n","Validation Epoch: 1\n","Loss: 1.5053 Accuracy: 68.75: 100%|██████████| 157/157 [00:42<00:00,  3.71it/s]  \n","Metrics of an epoch:  {'loss': 1.5573838478440691, 'accuracy': 0.6173}\n","Train Epoch: 2\n","Loss: 1.1698 Accuracy: 75.0: 100%|██████████| 1563/1563 [12:06<00:00,  2.15it/s]   \n","Validation Epoch: 2\n","Loss: 1.4367 Accuracy: 68.75: 100%|██████████| 157/157 [00:41<00:00,  3.78it/s]  \n","Metrics of an epoch:  {'loss': 1.4203944198644844, 'accuracy': 0.6448}\n","Train Epoch: 3\n","Loss: 1.5037 Accuracy: 62.5: 100%|██████████| 1563/1563 [12:19<00:00,  2.11it/s]   \n","Validation Epoch: 3\n","Loss: 1.3763 Accuracy: 75.0: 100%|██████████| 157/157 [00:41<00:00,  3.76it/s]   \n","Metrics of an epoch:  {'loss': 1.3589025200552243, 'accuracy': 0.6562}\n","Train Epoch: 4\n","Loss: 1.7282 Accuracy: 56.25: 100%|██████████| 1563/1563 [12:20<00:00,  2.11it/s]  \n","Validation Epoch: 4\n","Loss: 1.0493 Accuracy: 81.25: 100%|██████████| 157/157 [00:42<00:00,  3.70it/s]  \n","Metrics of an epoch:  {'loss': 1.322528057037645, 'accuracy': 0.6622}\n","Train Epoch: 5\n","Loss: 1.0233 Accuracy: 71.875: 100%|██████████| 1563/1563 [12:17<00:00,  2.12it/s] \n","Validation Epoch: 5\n","Loss: 1.0648 Accuracy: 81.25: 100%|██████████| 157/157 [00:42<00:00,  3.72it/s]  \n","Metrics of an epoch:  {'loss': 1.26879594660109, 'accuracy': 0.6771}\n","Train Epoch: 6\n","Loss: 1.4782 Accuracy: 68.75: 100%|██████████| 1563/1563 [12:09<00:00,  2.14it/s]  \n","Validation Epoch: 6\n","Loss: 1.029 Accuracy: 87.5: 100%|██████████| 157/157 [00:41<00:00,  3.81it/s]    \n","Metrics of an epoch:  {'loss': 1.254748994947239, 'accuracy': 0.6801}\n","Train Epoch: 7\n","Loss: 1.0529 Accuracy: 75.0: 100%|██████████| 1563/1563 [12:18<00:00,  2.12it/s]   \n","Validation Epoch: 7\n","Loss: 1.2913 Accuracy: 68.75: 100%|██████████| 157/157 [00:42<00:00,  3.70it/s]  \n","Metrics of an epoch:  {'loss': 1.2379180196743862, 'accuracy': 0.6824}\n","Train Epoch: 8\n","Loss: 0.8743 Accuracy: 78.125: 100%|██████████| 1563/1563 [12:04<00:00,  2.16it/s] \n","Validation Epoch: 8\n","Loss: 0.9695 Accuracy: 81.25: 100%|██████████| 157/157 [00:41<00:00,  3.76it/s]  \n","Metrics of an epoch:  {'loss': 1.236897645292768, 'accuracy': 0.6824}\n","Train Epoch: 9\n","Loss: 0.8778 Accuracy: 71.875: 100%|██████████| 1563/1563 [12:23<00:00,  2.10it/s] \n","Validation Epoch: 9\n","Loss: 0.8395 Accuracy: 81.25: 100%|██████████| 157/157 [00:42<00:00,  3.70it/s]  \n","Metrics of an epoch:  {'loss': 1.2584694107626653, 'accuracy': 0.6837}\n"]}],"source":["train(model, n_epochs, train_dataloader, val_dataloader, optimizer, criterion, device)"]},{"cell_type":"markdown","metadata":{"id":"ImVW8_EXlRVZ"},"source":["### Проверка полученной accuracy"]},{"cell_type":"markdown","metadata":{"cell_id":13,"id":"FmR-elhJlRVZ"},"source":["После всех экспериментов которые вы проделали, выберите лучшую из своих моделей, реализуйте и запустите функцию `evaluate`. Эта функция должна брать на вход модель и даталоадер с валидационными данными и возврашать accuracy, посчитанную на этом датасете."]},{"cell_type":"code","execution_count":144,"metadata":{"cell_id":14,"execution":{"iopub.execute_input":"2021-11-21T20:44:41.132258Z","iopub.status.busy":"2021-11-21T20:44:41.131772Z","iopub.status.idle":"2021-11-21T20:45:13.312962Z","shell.execute_reply":"2021-11-21T20:45:13.311978Z","shell.execute_reply.started":"2021-11-21T20:44:41.132221Z"},"id":"3TGH0EFalRVb","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loss: 0.8395 Accuracy: 81.25: 100%|██████████| 157/157 [00:32<00:00,  4.88it/s]  \n","Оценка за это задание составит 6.123333333333333 баллов\n"]}],"source":["all_losses, predicted_labels, true_labels = validate(model, val_dataloader, criterion, device)\n","assert len(predicted_labels) == len(val_data)\n","accuracy = accuracy_score(true_labels, predicted_labels)\n","print(\"Оценка за это задание составит {} баллов\".format(min(10, (10 * (accuracy - 0.5)/ 0.3))))"]},{"cell_type":"markdown","metadata":{"cell_id":15,"id":"pT8vfPSolRVb"},"source":["### Отчёт об экспериментах \n","\n","так. \n","* я пробовал mobilenet и несколько resnet -18, 101\n","* аугментацию \n","* лучший оптимизатор - АдамВ с амсградом. СГД, Адам - не пошли\n","* лосс брал только кроссэнтропию\n","* батчи - лучший размер 64. меньше или больше - смерть(("]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
